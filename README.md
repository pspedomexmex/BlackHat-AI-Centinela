# üíÄ Black Hat AI - Centinela de Auditor√≠a T√©cnica (v4.5)

**Estado del proyecto:** üü¢ Beta / En desarrollo inicial.

Este proyecto es una herramienta de apoyo para estudiantes y profesionales de **Ingenier√≠a en Sistemas** y Ciberseguridad. Utiliza una arquitectura **RAG (Retrieval-Augmented Generation)** para realizar consultas t√©cnicas precisas sobre manuales de auditor√≠a locales, optimizando el rendimiento en hardware de consumo como el **AMD Ryzen 5 5600G**.

## ‚ö†Ô∏è Advertencias Legales y √âticas
- **Uso √âtico:** Esta herramienta ha sido dise√±ada exclusivamente con fines educativos y de auditor√≠a autorizada. El mal uso de la informaci√≥n generada es responsabilidad total del usuario.
- **Derechos de Autor:** Este repositorio NO incluye los manuales t√©cnicos (PDFs) ni la base de datos vectorial pre-cargada debido a restricciones de propiedad intelectual.
- **Sobre la Bibliograf√≠a:** El sistema es agn√≥stico; usted puede indexar sus propios manuales de certificaci√≥n (EC-Council, LPI, Offensive Security, etc.). Si desea conocer la lista de materiales utilizados en mis pruebas o tiene dudas sobre c√≥mo obtenerlos respetando los derechos de autor, puede enviarme un mensaje directo para orientarle sobre las fuentes oficiales.

## üöÄ Caracter√≠sticas Principales
- **Filtro de Honestidad:** El sistema est√° programado para no alucinar. Si el dato no existe en su biblioteca local, admitir√° ignorancia en lugar de inventar comandos.
- **Interfaz Visual:** Diferenciaci√≥n por colores ANSI (Verde para teor√≠a, Amarillo para c√≥digo, Cian para el operador).
- **Privacidad Total:** Todo se ejecuta de forma local mediante **Ollama (Phi-3:mini)**. No se env√≠an datos a la nube.

## üõ†Ô∏è Requisitos del Sistema y Configuraci√≥n

Para que el **Centinela v4.5** funcione correctamente en su entorno local, siga este orden de instalaci√≥n:

### 1. Instalaci√≥n del Motor de IA (Ollama)
Este proyecto utiliza **Ollama** como motor de inferencia local para garantizar la soberan√≠a de los datos.

* **Instalar en Linux (Kali/Ubuntu/Debian):**

      curl -fsSL [https://ollama.com/install.sh](https://ollama.com/install.sh) | sh
  
Descargar el modelo t√©cnico: Utilizamos phi3:mini por su excelente equilibrio entre precisi√≥n t√©cnica y bajo consumo de recursos (ideal para los 2GB de VRAM de la iGPU del Ryzen 5600G).

    ollama pull phi3:mini



### 2. Preparaci√≥n del Entorno Python
Se recomienda el uso de un entorno virtual (Conda o venv).



### 3. Instalar dependencias
    pip install -r config/requirements.txt



#### 4. arga de Conocimiento (Indexaci√≥n)
Para alimentar la base de datos con sus propios manuales:
Coloque sus archivos PDF en la carpeta docs/.
Ejecute el script procesador desde la ra√≠z:

    python3 scripts/indexador_blackhat.py
Esto generar√° la carpeta db_vectorial/ en la ra√≠z del proyecto.


### 5. Ejecuci√≥n del Auditor Centinela
Una vez indexados los documentos, inicie la interfaz de consulta:

    python3 scripts/chat_blackhat.py  


üìã Metodolog√≠a de Uso
Consulta T√©cnica: Realice preguntas sobre protocolos, vulnerabilidades o comandos espec√≠ficos.

Respuesta Auditada: El sistema buscar√° en sus manuales locales. Si la informaci√≥n no est√° presente, el filtro de integridad le informar√° que no hay evidencia documental.

C√≥digo Seguro: Los fragmentos de c√≥digo se resaltar√°n en amarillo para diferenciarlos de la teor√≠a (verde).

Desarrollado por Edgar - Ingenier√≠a en Sistemas 2026
